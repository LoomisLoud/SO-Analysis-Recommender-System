{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important, to correctly see the graphs and the map of this notebook, click on this link : https://nbviewer.jupyter.org/github/agpmilli/network-tour-so/blob/master/StackOverflow.ipynb\n",
    "# EE-558 - Network tour of Data Science \n",
    "## Project: Stack Overflow survey network analysis\n",
    "\n",
    "### Authors\n",
    "Romain Choukroun, Matthias Leroy, Alain Milliet, Hector Parmantier\n",
    "\n",
    "### Question\n",
    "\n",
    "What's the best developer job like ? (depending on your own definition\n",
    "of \"best\")\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We used the dataset provided by [StackOverflow on\n",
    "Kaggle](https://www.kaggle.com/stackoverflow/so-survey-2017/data), you can download it and directly run the notebook. It contains about fifty thousand answers from a\n",
    "sample of the active StackOverflow population about a lot of questions,\n",
    "namely 154. This means that we have a tremendous insight into what\n",
    "makes a programmer unique, but we also can answer a lot of\n",
    "interesting questions.\n",
    "\n",
    "### Project\n",
    "\n",
    "#### Exploratory\n",
    "\n",
    "Check the distributions of all useful features, outliers, quantiles.\n",
    "Questions we could answer with the exploration:\n",
    "\n",
    "-   What features are more correlated with satisfaction?\n",
    "        Does salary equates to happiness/fulfilment in your job ?\n",
    "        How much is Job Satisfaction linked to education ?\n",
    "        Are \"gif\" people more satisfied with their job compared to \"jif\" people ?\n",
    "\n",
    "-   What does the population that answered to this survey looks like ?\n",
    "-   Can we find what are the most used programming languages in the StackOverflow population ?\n",
    "    \n",
    "#### Metric\n",
    "Derive a metric to measure the distance inbetween users\n",
    "\n",
    "#### Pre-processing\n",
    "\n",
    "Data cleaning, categorize values, check out their distribution,\n",
    "selecting columns, removing bad values if needed.\n",
    "\n",
    "#### Graph Analysis\n",
    "\n",
    "The graph will be built the following way:\n",
    "\n",
    "-   Users will be the nodes\n",
    "\n",
    "-   Correlations (with a threshold) in-between users used as edges\n",
    "\n",
    "#### Recommender System\n",
    "\n",
    "The idea of the recommender system is to be able to recommend users\n",
    "to recruiters. To do so, we would simply check\n",
    "which existing node is the closest to the artificial one that we create\n",
    "for the chosen features a recruiter is looking for.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a few utilities\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from helper_functions import *\n",
    "from plotly import tools\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "from scipy.stats import ks_2samp\n",
    "from subprocess import check_output\n",
    "import colorlover as cl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import warnings\n",
    "init_notebook_mode()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the data\n",
    "stack = pd.read_csv(\"data/survey_results_public.csv\")\n",
    "\n",
    "# We only keep the following columns \n",
    "# for the analysis and the recommender system\n",
    "kept_columns = ['Respondent', 'Professional', 'ProgramHobby', 'Country', 'University', 'EmploymentStatus', 'FormalEducation', 'MajorUndergrad', 'CompanySize', 'CompanyType', 'YearsProgram', 'YearsCodedJob', 'DeveloperType', 'WebDeveloperType', 'NonDeveloperType', 'CareerSatisfaction', 'JobSatisfaction', 'PronounceGIF', 'ProblemSolving', 'BuildingThings', 'LearningNewTech', 'BoringDetails', 'JobSecurity', 'DiversityImportant', 'FriendsDevelopers', 'WorkPayCare', 'ChallengeMyself', 'ImportantBenefits', 'ClickyKeys', 'Overpaid', 'TabsSpaces', 'EducationImportant', 'EducationTypes', 'SelfTaughtTypes', 'WorkStart', 'HaveWorkedLanguage', 'WantWorkLanguage', 'IDE', 'AuditoryEnvironment', 'Methodology', 'EquipmentSatisfiedMonitors', 'StackOverflowSatisfaction', 'StackOverflowFoundAnswer', 'StackOverflowCopiedCode', 'StackOverflowWhatDo', 'Gender', 'HighestEducationParents', 'Race', 'Salary', \"ExpectedSalary\"]\n",
    "stack = stack[kept_columns]\n",
    "stack.set_index(\"Respondent\", inplace=True)\n",
    "stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into \n",
    "# students and professionals\n",
    "stack = stack[stack.apply(lambda row: row_filter(stack,row), axis=1)]\n",
    "prof_stack = stack[stack.Professional == \"Professional developer\"]\n",
    "stud_stack = stack[stack.Professional == \"Student\"]\n",
    "\n",
    "metadata = pd.read_csv(\"data/survey_results_schema.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "In this section we will explore different columns of our dataframe to have an idea of what the population we have looks like. We decided to split the professionals and the students such that we can obtain 2 different recommender systems in function of what the recruiter is looking for. For certain features, it makes sense to compare the professionals and the students but for some others it makes more sense to do some statistics on the whole data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Professional\n",
    "In this subsection we want to see the proportion of professionals and students we have in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack['Professional'].value_counts()[0:10].plot(kind='bar',figsize=(5,5))\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this graph, we can see the proportion of professionals and students in our dataset. As we can see, there are a lot more professionals than students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country\n",
    "We wanted to know from what country the people that answered to the survey come. As we have more professionals than students, we decided to take the 10 countries with the biggest number of professionals and from there we mapped the number of students for thes countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stud_prof(prof_stack=prof_stack, stud_stack=stud_stack, column='Country', title=\"Country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this graph, we can see that the percentage of professionals is not always proportional to the percentage of students in the same country. The United States and India are the two most obvious ones. While 30% of professionals come from the USA, less than 20% of the students come from there. On the other hand, only 5% of professionals in our data come from India while nearly 15% of students come from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developer Type\n",
    "This subsection concerns the type of developer we can find in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DevTypes = pd.Series([devtype for sublist in [str(devtypes).replace(\" \", \"\").split(\";\") for devtypes in stack['DeveloperType'].dropna()] for devtype in sublist])\n",
    "DevTypes.value_counts(normalize=True)[0:10].plot(kind='bar',figsize=(7,7))\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an observation, we can say that the major part of the population in our dataset define themself as Web Developper. But this result does not give that much information as there are multiple types of Web developpers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Languages\n",
    "As the previous section was about the type of developper we wanted to see if the programming languages correspond to the these types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_languages = pd.Series([lang for sublist in [str(langs).replace(\" \", \"\").split(\";\") for langs in prof_stack['HaveWorkedLanguage'].dropna()] for lang in sublist])\n",
    "stud_languages = pd.Series([lang for sublist in [str(langs).replace(\" \", \"\").split(\";\") for langs in stud_stack['HaveWorkedLanguage'].dropna()] for lang in sublist])\n",
    "plot_stud_prof(prof=prof_languages, stud=stud_languages, title=\"Languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It looks like it corresponds pretty well as the most important programming language we find is directly linked to the Web Development. We were interested in knowing what were the most important languages per country, so we decided to plot them on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We prepare the data for the map\n",
    "codes = [MAP_COUNTRIES[country] if country != 'I prefer not to say' else None for country in stack['Country']]\n",
    "stack['Code']=codes\n",
    "\n",
    "country_stack = stack[['HaveWorkedLanguage','Code']]\n",
    "country_stack[\"HaveWorkedLanguage\"] = country_stack[\"HaveWorkedLanguage\"].apply(lambda x: str(x).replace(\" \", \"\").split(\";\"))\n",
    "country_stack = country_stack.set_index('Code')\n",
    "\n",
    "language_country = pd.get_dummies(pd.DataFrame(country_stack['HaveWorkedLanguage'].tolist(), index=country_stack.index).stack()).sum(level=0)\n",
    "language_country = language_country.T.idxmax()\n",
    "languages = list(language_country.unique())\n",
    "languages.remove('nan')\n",
    "\n",
    "# Get a 12 colors scale\n",
    "paired = cl.scales['12']['qual']['Paired']\n",
    "# Create dict between language and color\n",
    "language_color_dict = {}\n",
    "for i, language in enumerate(languages):\n",
    "    language_color_dict[language]=paired[i]\n",
    "# Create dict between language and countries\n",
    "language_country_dict = {}\n",
    "for index, row in language_country.iteritems():\n",
    "    if row in language_country_dict:\n",
    "        language_country_dict[row].append(index)\n",
    "    else:\n",
    "        language_country_dict[row]=[index]\n",
    "\n",
    "data = []\n",
    "for i, lang in enumerate(languages):\n",
    "    trace1 = go.Choropleth(\n",
    "        z=['1']*len(language_country_dict[lang]),\n",
    "        autocolorscale=False,\n",
    "        colorscale=[[0, 'rgb(255,255,255)'], [1, language_color_dict[lang]]],\n",
    "        hoverinfo='text',\n",
    "        locations=language_country_dict[lang],\n",
    "        name=lang,\n",
    "        showscale=False,\n",
    "        text=lang\n",
    "    )\n",
    "    data.append(trace1)\n",
    "layout = dict(\n",
    "    title = 'Most represented programming language per country',\n",
    "    geo = dict(\n",
    "            projection = dict(\n",
    "                type = 'Mercator'\n",
    "            ),\n",
    "            showframe=False\n",
    "            )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see on this map the real importance of StackOverflow for Javascript developers around the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Satisfaction\n",
    "In this case, we wanted to see how satisfied of their job the people in our dataset are. We compared the job satisfation with the career satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the satisfaction of each surveyee\n",
    "jobSat = stack['JobSatisfaction']/stack['JobSatisfaction'].max()\n",
    "carrSat = stack['CareerSatisfaction']/stack['CareerSatisfaction'].max()\n",
    "j_satisfaction = jobSat.value_counts(normalize=True).sort_index()\n",
    "carr = carrSat.value_counts(normalize=True)\n",
    "c_satisfaction = carr.loc[j_satisfaction.index]\n",
    "df = pd.DataFrame([j_satisfaction, c_satisfaction])\n",
    "df = df.T\n",
    "df.columns = [\"Job Satisfaction\", \"Career Satisfaction\"]\n",
    "df.plot.bar(figsize=(7,7))\n",
    "plt.title('Satisfaction')\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It is pretty clear on the graph above that the job satisfaction and the career satisfaction are directly linked. To remove all bias such as a person that votes 4 for the job and 8 for the career while another person votes 8 for the job and 4 for the career, we decided to look at the difference between these values and see if we have a lot of people having that much difference between their satisfactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "satisfaction = stack[['JobSatisfaction','CareerSatisfaction']]\n",
    "satisfaction['Difference']= np.abs(satisfaction['JobSatisfaction']-satisfaction['CareerSatisfaction'])\n",
    "satisfaction['Difference'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in general people give approximately the same satisfaction score to their job and to their career. It means that the distribution seen above is correct. Let's now see what causes the developers to be happy or unhappy in their professional life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep the columns liked to satisfaction, \n",
    "# we mean them together and normalize the result\n",
    "satisfaction_mean = prof_stack[[\"JobSatisfaction\", \"CareerSatisfaction\"]].mean(axis=1)\n",
    "satisfaction_mean = (satisfaction_mean - satisfaction_mean.min()) / (satisfaction_mean.max() - satisfaction_mean.min())\n",
    "\n",
    "# Separate the other factors\n",
    "other_factors = prof_stack.drop([\"StackOverflowSatisfaction\", \"CareerSatisfaction\", \"JobSatisfaction\", \"ExpectedSalary\"], axis=1)\n",
    "other_factors = other_factors.fillna(\"\")\n",
    "\n",
    "# In order to measure the correlation we need \n",
    "# to encode the labels need to encode the \n",
    "# labels to measure the correlation\n",
    "for c in other_factors.columns:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(other_factors[c])\n",
    "    other_factors[c] = le.transform(other_factors[c])\n",
    "    \n",
    "# Which columns does the satisfaction correlate the most with ?\n",
    "most_satisfactory = other_factors.corrwith(satisfaction_mean).nlargest(10)\n",
    "most_satisfactory.plot.bar()\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.xlabel(\"Other factors\")\n",
    "plt.title(\"Column correlation for the measure of satisfaction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we can see that the more people have a high salary, the more satisfied they are. Interestingly, it also correlates with general welness at work, for example the equipment, or the environnement, but also with their free time ! They see to be more happy if they program as a hobby and if they build stuff on their own. Finally, obviously the biggest factors like Country, Education and Race matter a lot too, which was to be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity Important\n",
    "In this section we will analyze if professionals and students give the same importance to the diversity at their job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stud_prof(prof_stack=prof_stack, stud_stack=stud_stack, column='DiversityImportant', title=\"Diversity Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can pretty easily see that the two distributions are really close and it seems to not be different between professionals and students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salaries\n",
    "Let's take a look at how the salaries compare for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (box, dist) = plt.subplots(nrows=1, ncols=2, figsize=(10,6))\n",
    "f.subplots_adjust(wspace=0.7)\n",
    "\n",
    "# Boxplot of the salaries\n",
    "sns.boxplot(prof_stack.Salary, orient='v', ax=box)\n",
    "box.set_title(\"Box-plot of the total salaries\")\n",
    "\n",
    "# Comparing India and the USA salary-wise\n",
    "usa_salary = prof_stack[prof_stack.Country == \"United States\"].Salary\n",
    "usa_salary.rename(\"United States\", inplace=True)\n",
    "india_salary = prof_stack[prof_stack.Country == \"India\"].Salary\n",
    "india_salary.rename(\"India\", inplace=True)\n",
    "india_salary.plot.kde(legend=True, ax=dist)\n",
    "usa_salary.plot.kde(legend=True, ax=dist)\n",
    "dist.set_title(\"Salary distribution\")\n",
    "dist.set_xlabel(\"Salary in USD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the boxplot shows that we have a high breadth of salaries. If we compare the distribution of two different countries, we can see why, each country simply have their own revenue model for the profession. What about the students, do they their salary expectation meet the reality or not ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compare the student expectations to the young professionals\n",
    "stud_stack.ExpectedSalary.plot(kind='kde', figsize=(10,8), color='r', legend=True)\n",
    "prof_stack[(prof_stack.YearsProgram == \"Less than a year\")].Salary.plot(kind='kde', figsize=(7,7), legend=True)\n",
    "plt.xlabel(\"Salary/Expected Salary in USD\")\n",
    "plt.title(\"Distribution of expected salary and salary for the students and professionals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, they match quite nicely ! Students are not the highest dreamers after all.\n",
    "\n",
    "Another really important aspect concerning the salary is the equality inbetween women and men. Let's verify that it holds for the StackOverflow community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_salary = stack[stack.Gender == \"Female\"].Salary\n",
    "male_salary = stack[stack.Gender == \"Male\"].Salary\n",
    "male_salary.rename(\"Male\", inplace=True)\n",
    "female_salary.rename(\"Female\", inplace=True)\n",
    "print(\"There are {} male samples and {} female samples.\".format(male_salary.count(), female_salary.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the samples are really unequal, so it would be unwise to try and draw any conclusions as the salaries are supposedly quite close to one another. We decided instead to take it very seriously and run a pairwise-matching to find a one to one mapping of each woman to a man, without taking into account the salary, and then check the distributions. This way the comparisons will make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We select the columns to use as features\n",
    "similarity_features = ['Country', 'University',\n",
    "       'EmploymentStatus', 'FormalEducation', 'CompanySize',\n",
    "       'CompanyType', 'YearsCodedJob', 'DeveloperType',\n",
    "       'WebDeveloperType', 'NonDeveloperType',\n",
    "       'EducationTypes', 'HaveWorkedLanguage', 'Methodology',\n",
    "       'HighestEducationParents', 'Race']\n",
    "\n",
    "# The following columns we want a 1 to 1 matching for\n",
    "# as they are the most important features\n",
    "perfect_matches = ['Country', 'EmploymentStatus', 'FormalEducation', \n",
    "                   'YearsCodedJob','HighestEducationParents', 'Race']\n",
    "\n",
    "sim_stack = prof_stack[similarity_features].copy()\n",
    "to_dummy = [\"HaveWorkedLanguage\", \"DeveloperType\", \"Methodology\", \"EducationTypes\", \"NonDeveloperType\", \"Race\"]\n",
    "for sub in to_dummy:\n",
    "    sim_stack[sub] = sim_stack[sub].apply(lambda x: str(x).replace(\" \", \"\").split(\";\"))\n",
    "    if sub == \"Race\":\n",
    "        sim_stack[sub] = sim_stack[sub].apply(lambda x: [\"Race_\" + s for s in x])\n",
    "    sim_stack = pd.concat([sim_stack, pd.get_dummies(pd.DataFrame(sim_stack[sub].tolist(), index=sim_stack.index).stack()).sum(level=0)], axis=1).drop(sub, axis=1)\n",
    "\n",
    "# Final dummies we will be using\n",
    "dummied_prof = pd.get_dummies(sim_stack)\n",
    "dum_female = dummied_prof[prof_stack.Gender == \"Female\"]\n",
    "dum_male = dummied_prof[prof_stack.Gender == \"Male\"]\n",
    "\n",
    "# We load the data from a pickle for\n",
    "# speed otherwise, change the constant\n",
    "load_from_pickle = False\n",
    "matching = pd.DataFrame(index=dum_female.index, columns=[\"male_matched\", \"correlation\"])\n",
    "for i,fem in enumerate(matching.index):\n",
    "    print(\"Progress: {:.2f}%\".format((i+1)/matching.shape[0]*100), end=\"\\r\")\n",
    "    # We match the following female\n",
    "    female_to_match = dum_female.loc[fem]\n",
    "\n",
    "    # We want an exact match for the \n",
    "    # specified columns in the previous cell\n",
    "    perfect_columns = [col for c in perfect_matches for col in dum_male if col.startswith(c) ]\n",
    "    male_possibilities = dum_male[(dum_male[perfect_columns] == female_to_match[perfect_columns]).all(axis=1)]\n",
    "\n",
    "    # For the other columns, we select \n",
    "    # the closest sample correlation-wise\n",
    "    correlations = male_possibilities.drop(perfect_columns, axis=1).corrwith(dum_female.drop(perfect_columns, axis=1).loc[fem], axis=1)\n",
    "\n",
    "    # If we find no perfect match, the\n",
    "    # female sample is discarded\n",
    "    if correlations.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    # Select the best male match and remove \n",
    "    # it from all possible matches\n",
    "    best_match = correlations.idxmax()\n",
    "    dum_male.drop(best_match, inplace=True)\n",
    "    matching.loc[fem][\"male_matched\"] = best_match\n",
    "    matching.loc[fem][\"correlation\"] = correlations.max()\n",
    "\n",
    "# Remove the unmatched pairs\n",
    "matching.dropna(inplace=True)\n",
    "\n",
    "matching = matching.reset_index()\n",
    "matched_indices = matching.T.iloc[0].tolist() + matching.T.iloc[1].tolist()\n",
    "matched_data = prof_stack.loc[matched_indices]\n",
    "male_salary = matched_data[matched_data.Gender == \"Male\"].Salary\n",
    "female_salary = matched_data[matched_data.Gender == \"Female\"].Salary\n",
    "male_salary.rename(\"Male\", inplace=True)\n",
    "female_salary.rename(\"Female\", inplace=True)\n",
    "\n",
    "# Let's plot it\n",
    "male_salary.plot.kde(color=\"r\", legend=True, figsize=(10,8))\n",
    "female_salary.plot.kde(legend=True, figsize=(10,8))\n",
    "plt.title(\"Distribution of male and female salaries\")\n",
    "plt.show()\n",
    "\n",
    "# We perform a Kolmogorov-Smirnoff test\n",
    "statistic, p_value = ks_2samp(female_salary, male_salary)\n",
    "print(\"We get a statistic of {:.4f} and a p_value of {:.4f} for {} male samples and {} female samples.\"\n",
    "     .format(statistic, p_value, male_salary.count(), female_salary.count()))\n",
    "\n",
    "# We also take a look at the quartiles\n",
    "\n",
    "print(\"\\nThe male salaries quartiles:\\n{}\".format(male_salary.describe()))\n",
    "print(\"\\nThe female salaries quartiles:\\n{}\".format(female_salary.describe()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the p-value is above the 0.05 threshold we cannot reject the hypothesis that the salary samples are drawn from the same distribution. Which is confirmed by the low statistic. We can also see that the distribution of the female salaries is a bit to the left compared to the men one, which is confirmed by the quartiles, where we see the men winning mostly in that regard.\n",
    "\n",
    "Still, we should be reminded of the fact that we have only 447 samples of each population, which might not be enough to base any conclusion off of.\n",
    "## Personal Attributes\n",
    "To get a final feel of the data, we take a look at the distribution of genders and races of the respondents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (race, gender) = plt.subplots(nrows=1, ncols=2, figsize=(10,6))\n",
    "f.subplots_adjust(wspace=0.7)\n",
    "\n",
    "prof_stack.Race.value_counts(normalize=True)[0:6].plot(kind='bar', ax=race)\n",
    "race.set_title(\"Distribution of the races\")\n",
    "race.set_ylabel(\"Ratio\")\n",
    "\n",
    "prof_stack.Gender.value_counts(normalize=True)[0:4].plot(kind='bar', ax=gender)\n",
    "gender.set_title(\"Distribution of the genders\")\n",
    "gender.set_ylabel(\"Ratio\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no surprise, the majority of respondents are white males.\n",
    "## Education types\n",
    "Another interesting thing to know is how these developers learned to code. Do the students and professionals learned the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_education = pd.Series([ed for sublist in [str(educs).replace(\" \", \"\").split(\";\") for educs in prof_stack['EducationTypes'].dropna()] for ed in sublist])\n",
    "stud_education = pd.Series([ed for sublist in [str(educs).replace(\" \", \"\").split(\";\") for educs in stud_stack['EducationTypes'].dropna()] for ed in sublist])\n",
    "plot_stud_prof(prof=prof_education, stud=stud_education, title=\"Education types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again without any surprise, the distributions are quite the same, appart from the ones linked to the job/student life, for example students are more likely to learn using online courses and professional using on-the-job training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIF vs JIF\n",
    "\n",
    "Here we wanted to see the distribution of a funny feature we have access too, which is the distribution of the salary in function of the pronunciation of the term \"GIF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gif_df = stack[[\"PronounceGIF\", \"Salary\"]].dropna(how='any')\n",
    "gif_df = gif_df.set_index(\"PronounceGIF\")\n",
    "g_df = gif_df.loc['With a hard \"g,\" like \"gift\"'].Salary.values\n",
    "j_df = gif_df.loc['With a soft \"g,\" like \"jiff\"'].Salary.values\n",
    "comparing_df = pd.DataFrame()\n",
    "comparing_df['gif'] = pd.Series(g_df)\n",
    "\n",
    "# We fill the empty values\n",
    "filling = np.empty((6081))\n",
    "filling[:] = np.nan\n",
    "to_add = np.append(j_df, filling)\n",
    "comparing_df['jif'] = pd.Series(to_add)\n",
    "\n",
    "# Let's check it out\n",
    "plot = sns.boxplot(data=comparing_df, orient=\"v\",)\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.title(\"Distribution of salary for the gif and jif populations\")\n",
    "plt.show()\n",
    "\n",
    "print(comparing_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can quickly see, there is not much difference inbetween the gif people and the jif people in terms of salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Recommender system\n",
    "\n",
    "In this section we created a recommender system to help recruiters find the candidates they are looking for. The idea is to create a network using the individuals as nodes and their similarity as the weights of the edges. Recruiters can ask for certain skills/education/locations and we will show them the closest entities to their request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep important features\n",
    "important_features_prof = ['ProgramHobby', 'Country', 'University', 'FormalEducation', 'MajorUndergrad', 'CompanyType'\n",
    "                           ,'YearsCodedJob', 'YearsProgram', 'DeveloperType', 'CareerSatisfaction', 'JobSatisfaction', 'Overpaid'\n",
    "                           , 'HaveWorkedLanguage', 'WantWorkLanguage']\n",
    "\n",
    "\n",
    "important_features_stud = ['ProgramHobby', 'Country', 'University', 'FormalEducation', 'YearsProgram','WorkStart',\n",
    "                            'HaveWorkedLanguage', 'WantWorkLanguage', 'AuditoryEnvironment']\n",
    "\n",
    "final_prof_stack = prof_stack[important_features_prof].copy()\n",
    "final_stud_stack = stud_stack[important_features_stud].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compute the k-nearest neighbors of each individual in our dataset and plot them on the corresponding graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a  look at the students network\n",
    "preprocessed_dfs_stud = preprocessed(final_stud_stack, [\"HaveWorkedLanguage\", \"WantWorkLanguage\"],'WantWorkLanguage', False)\n",
    "G_stud, pos_stud = draw_graph(compute_knn_graph(preprocessed_dfs_stud[0]), \"Network containing StackOverflow's students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, onto the professionals network\n",
    "preprocessed_dfs_prof = preprocessed(final_prof_stack, [\"HaveWorkedLanguage\", \"WantWorkLanguage\", 'DeveloperType'],'WantWorkLanguage', True)\n",
    "G_prof, pos_prof = draw_graph(compute_knn_graph(preprocessed_dfs_prof[0]), \"Network containing StackOverflow's professionals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have less students than professionals we can see that the network with students is more sparse.\n",
    "\n",
    "Afterwards, we wanted to see the patterns we could find in our network due to the important features we declared above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "map_stud, df_encode_stud = encode_label(preprocessed_dfs_stud[1], important_features_stud)\n",
    "map_prof, df_encode_prof = encode_label(preprocessed_dfs_prof[1], important_features_prof)\n",
    "\n",
    "# A few features for the student's network\n",
    "draw_features(important_features_stud, df_encode_stud, map_stud, G_stud, pos_stud, \"student's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A few features for the professional's network\n",
    "draw_features(important_features_prof, df_encode_prof, map_prof, G_prof, pos_prof, \"professional's\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, coloring the most important features creates clusters that we can directly see, which is to be expected.\n",
    "\n",
    "# Predict\n",
    "\n",
    "In this last section we show an example of a prediction on a given request of a recruiter, both in the students' space and in the professionnals' space. Since we use a one-hot encoder, omitting one answer of these questions is not a problem for the recommender system.\n",
    "\n",
    "## Student\n",
    "\n",
    "Here is the request of the students' recruiter:\n",
    "- Do you program as a hobby or contribute to open source projects?: **Yes, both**\n",
    "- In which country do you currently live?: **France**\n",
    "- Are you currently enrolled in a formal, degree-granting college or university program?: **No**\n",
    "- Which of the following best describes the highest level of formal education that you've completed?: **Secondary school**\n",
    "- How long has it been since you first learned how to program?: **2 to 3 years**\n",
    "- Suppose you could choose your own working hours for an 8-hour day. What time would you start work for the day? Please adjust the slider to the hour nearest your ideal start time. The box next to the slider will display your selection using a 24-hour clock: **10:00 AM**\n",
    "- Which of the following languages have you done extensive development work in over the past year, and which do you want to work in over the next year?: **C#, Java**\n",
    "- Which of the following languages have you done extensive development work in over the past year, and which do you want to work in over the next year?: **C++, Python**\n",
    "- Suppose you're about to start a few hours of coding and have complete control over your auditory environment (music, background noise, etc.). What would you do?: **Turn on some music**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stud_stack.loc[final_stud_stack.shape[0]] = ['Yes, both', 'France', 'No', 'Secondary school', '2 to 3 years', '10:00 AM', 'C#, Java',\n",
    "                                                  'C++, Python', 'Turn on some music']\n",
    "predict_dfs_stud = preprocessed(final_stud_stack, [\"HaveWorkedLanguage\", \"WantWorkLanguage\"],\n",
    "                                          'WantWorkLanguage', False)\n",
    "knn_stud = compute_knn_graph(predict_dfs_stud[0])\n",
    "\n",
    "best_predict_stud = np.argsort(knn_stud.toarray()[-1])[::-1][1:6]\n",
    "size_stud = preprocessed_dfs_stud[1].shape[0]\n",
    "predict_dfs_stud[1].iloc[[size_stud-1] + list(best_predict_stud), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_stud = nx.from_scipy_sparse_matrix(knn_stud, edge_attribute='similarity')\n",
    "pos_stud = nx.spring_layout(G_stud)\n",
    "draw_neighbors(G_stud, pos_stud, size_stud-1, \"Neighbors of our recruiter's node in student's network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In black is the node formed by the recruiter and his answers to the questions, then in red we can see the recommendations that we will provide him with while the rest of the nodes are in blue. We can see that the nodes are not that far from one another, even if they seem so, this is due to the fact that the real network is embedded in about 15 dimensions, and is impossible to see for the human eye. However we can confirm through the KNN algorithm that they are in fact the closest nodes to our recruiter's answers.\n",
    "\n",
    "## Professional \n",
    "\n",
    "Here is the request of the professionals' recruiter:\n",
    "- Do you program as a hobby or contribute to open source projects?: **Yes, both**\n",
    "- In which country do you currently live?: **United Kingdom**\n",
    "- Are you currently enrolled in a formal, degree-granting college or university program?: **No**\n",
    "- Which of the following best describes the highest level of formal education that you've completed?: **Bachelor's degree**\n",
    "- Which of the following best describes your main field of study (aka 'major') in college or university/for your undergraduate studies?: **Computer science or software engineering**\n",
    "- Which of the following best describes the type of company or organization you work for?: **Publicly-traded corporation**\n",
    "- For how many years have you coded as part of your job?: **20 or more years**\n",
    "- How long has it been since you first learned how to program?: **20 or more years**\n",
    "- Which of the following best describe you?: **Other**\n",
    "- Career satisfaction rating: **8.0**\n",
    "- Job satisfaction rating: **9.0**\n",
    "- Compared to your estimate of your own market value, do you think you are…?: **Neither underpaid nor overpaid**\n",
    "- Which of the following languages have you done extensive development work in over the past year, and which do you want to work in over the next year?: **Java, PHP, Python**\n",
    "- Which of the following languages have you done extensive development work in over the past year, and which do you want to work in over the next year?: **C, Python, Rust**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prof_stack.loc[final_prof_stack.shape[0]] = ['Yes, both', 'United Kingdom', 'No', \"Bachelor's degree\", 'Computer science or software engineering', \n",
    "                                                   'Publicly-traded corporation', '20 or more years', '20 or more years', 'Other', \n",
    "                                                   8.0, 9.0, 'Neither underpaid nor overpaid', 'Java; PHP; Python', \n",
    "                                                   'C; Python; Rust']\n",
    "\n",
    "predict_dfs_prof = preprocessed(final_prof_stack, [\"HaveWorkedLanguage\", \"WantWorkLanguage\", \"DeveloperType\"],\n",
    "                                          'WantWorkLanguage', True)\n",
    "\n",
    "knn_prof = compute_knn_graph(predict_dfs_prof[0])\n",
    "best_predict_prof = np.argsort(knn_prof.toarray()[-1])[::-1][1:6]\n",
    "\n",
    "size_prof = preprocessed_dfs_prof[1].shape[0]\n",
    "predict_dfs_prof[1].iloc[[size_prof-1] + list(best_predict_prof), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_prof = nx.from_scipy_sparse_matrix(knn_prof, edge_attribute='similarity')\n",
    "pos_prof = nx.spring_layout(G_prof)\n",
    "draw_neighbors(G_prof, pos_prof, size_prof-1, \"Neighbors of our recruiter's node in professional's network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO COMMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
