{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE-558 - Network tour of Data Science \n",
    "## Project: Stack Overflow survey network analysis\n",
    "\n",
    "### Authors\n",
    "Romain Choukroun, Matthias Leroy, Alain Milliet, Hector Parmantier\n",
    "\n",
    "### Question\n",
    "\n",
    "What's the best developer job like ? (depending on your own definition\n",
    "of \"best\")\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset provided by [StackOverflow on\n",
    "Kaggle](https://www.kaggle.com/stackoverflow/so-survey-2017/data) seems\n",
    "to be a great start. It contains about fifty thousand answers from a\n",
    "sample of the active StackOverflow population about a lot of questions,\n",
    "namely 154. This means that we would have a tremendous insight into what\n",
    "makes a programmer unique, but also can help us to answer a lot of\n",
    "interesting questions.\n",
    "\n",
    "### Project\n",
    "\n",
    "#### Exploratory\n",
    "\n",
    "Check the distributions of all useful features, outliers, quantiles.\n",
    "Questions we could answer with the exploration:\n",
    "\n",
    "-   Does salary equates to happiness/fulfilment in your job ?\n",
    "\n",
    "-   For users not satisfied with their job, what should they change to\n",
    "    be more satisfied (use closest correlated neighbor) ?\n",
    "\n",
    "-   How much is Job Satisfaction linked to education ?\n",
    "\n",
    "-   Are \"gif\" people more satisfied with their job compared to \"jif\"\n",
    "    people ?\n",
    "    \n",
    "#### Metric\n",
    "Derive metric to measure happiness/fulfillment\n",
    "\n",
    "#### Pre-processing\n",
    "\n",
    "Data cleaning, categorize values, check out their distribution,\n",
    "selecting columns, removing bad values if needed.\n",
    "\n",
    "#### Feature Extraction\n",
    "\n",
    "PCA to check which are the features explaining the most variance.\n",
    "\n",
    "#### Graph Analysis\n",
    "\n",
    "The graph will be built the following way:\n",
    "\n",
    "-   Users will be the nodes\n",
    "\n",
    "-   Correlations (with a threshold) in-between users used as edges\n",
    "\n",
    "#### Recommender System\n",
    "\n",
    "The idea here would be to be able to recommend which of a set of users\n",
    "best represents a set of given goals. To do so, we would simply check\n",
    "which existing node is the closest to the artificial one that we create\n",
    "for the chosen features a recruiter is looking for.\n",
    "\n",
    "# Important\n",
    "To correctly see the graphs and the map of this notebook\n",
    "\n",
    "Click on this link :\n",
    "https://nbviewer.jupyter.org/github/agpmilli/network-tour-so/blob/master/StackOverflow.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "from helper_functions import plot_stud_prof, row_filter, MAP_COUNTRIES\n",
    "from plotly import tools\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from subprocess import check_output\n",
    "import colorlover as cl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import community\n",
    "from matplotlib import cm\n",
    "init_notebook_mode()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the data\n",
    "stack = pd.read_csv(\"data/survey_results_public.csv\")\n",
    "\n",
    "# We only keep the following columns \n",
    "# for the analysis and the recommender system\n",
    "kept_columns = ['Respondent', 'Professional', 'ProgramHobby', 'Country', 'University', 'EmploymentStatus', 'FormalEducation', 'MajorUndergrad', 'CompanySize', 'CompanyType', 'YearsProgram', 'YearsCodedJob', 'DeveloperType', 'WebDeveloperType', 'NonDeveloperType', 'CareerSatisfaction', 'JobSatisfaction', 'PronounceGIF', 'ProblemSolving', 'BuildingThings', 'LearningNewTech', 'BoringDetails', 'JobSecurity', 'DiversityImportant', 'FriendsDevelopers', 'WorkPayCare', 'ChallengeMyself', 'ImportantBenefits', 'ClickyKeys', 'Overpaid', 'TabsSpaces', 'EducationImportant', 'EducationTypes', 'SelfTaughtTypes', 'WorkStart', 'HaveWorkedLanguage', 'WantWorkLanguage', 'IDE', 'AuditoryEnvironment', 'Methodology', 'EquipmentSatisfiedMonitors', 'StackOverflowSatisfaction', 'StackOverflowFoundAnswer', 'StackOverflowCopiedCode', 'StackOverflowWhatDo', 'Gender', 'HighestEducationParents', 'Race', 'Salary', \"ExpectedSalary\"]\n",
    "stack = stack[kept_columns]\n",
    "stack.set_index(\"Respondent\", inplace=True)\n",
    "stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into \n",
    "# students and professionals\n",
    "stack = stack[stack.apply(lambda row: row_filter(stack,row), axis=1)]\n",
    "prof_stack = stack[stack.Professional == \"Professional developer\"]\n",
    "stud_stack = stack[stack.Professional == \"Student\"]\n",
    "\n",
    "metadata = pd.read_csv(\"data/survey_results_schema.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "In this section we will explore different columns of our dataframe to have an idea of what the population we have looks like. We decided to split the professionals and the students such that we can obtain 2 different recommender systems in function of what the recruiter is looking for. For certain features, it makes sense to compare the professionals and the students but for some others it makes more sense to do some statistics on the whole data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Professional\n",
    "In this subsection we want to see the proportion of professionals and students we have in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack['Professional'].value_counts()[0:10].plot(kind='bar',figsize=(5,5))\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this graph, we can see the proportion of professionals and students in our dataset. As we can see, there are a lot more professionals than students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country\n",
    "We wanted to know from what country the people that answered to the survey come. As we have more professionals than students, we decided to take the 10 countries with the biggest number of professionals and from there we mapped the number of students for thes countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stud_prof(prof_stack=prof_stack, stud_stack=stud_stack, column='Country', title=\"Country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this graph, we can see that the percentage of professionals is not always proportional to the percentage of students in the same country. The United States and India are the two most obvious ones. While 30% of professionals come from the USA, less than 20% of the students come from there. On the other hand, only 5% of professionals in our data come from India while nearly 15% of students come from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developer Type\n",
    "This subsection concerns the type of developer we can find in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DevTypes = pd.Series([devtype for sublist in [str(devtypes).replace(\" \", \"\").split(\";\") for devtypes in stack['DeveloperType'].dropna()] for devtype in sublist])\n",
    "DevTypes.value_counts(normalize=True)[0:10].plot(kind='bar',figsize=(7,7))\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an observation, we can say that the major part of the population in our dataset define themself as Web Developper. But this result does not give that much information as there are multiple types of Web developpers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Languages\n",
    "As the previous section was about the type of developper we wanted to see if the programming languages correspond to the these types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_languages = pd.Series([lang for sublist in [str(langs).replace(\" \", \"\").split(\";\") for langs in prof_stack['HaveWorkedLanguage'].dropna()] for lang in sublist])\n",
    "stud_languages = pd.Series([lang for sublist in [str(langs).replace(\" \", \"\").split(\";\") for langs in stud_stack['HaveWorkedLanguage'].dropna()] for lang in sublist])\n",
    "plot_stud_prof(prof=prof_languages, stud=stud_languages, title=\"Languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It looks like it corresponds pretty well as the most important programming language we find is directly linked to the Web Development. We were interested in knowing what were the most important languages per country, so we decided to plot them on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We prepare the data for the map\n",
    "codes = [MAP_COUNTRIES[country] if country != 'I prefer not to say' else None for country in stack['Country']]\n",
    "stack['Code']=codes\n",
    "\n",
    "country_stack = stack[['HaveWorkedLanguage','Code']]\n",
    "country_stack[\"HaveWorkedLanguage\"] = country_stack[\"HaveWorkedLanguage\"].apply(lambda x: str(x).replace(\" \", \"\").split(\";\"))\n",
    "country_stack = country_stack.set_index('Code')\n",
    "\n",
    "language_country = pd.get_dummies(pd.DataFrame(country_stack['HaveWorkedLanguage'].tolist(), index=country_stack.index).stack()).sum(level=0)\n",
    "language_country = language_country.T.idxmax()\n",
    "languages = list(language_country.unique())\n",
    "languages.remove('nan')\n",
    "\n",
    "# Get a 12 colors scale\n",
    "paired = cl.scales['12']['qual']['Paired']\n",
    "# Create dict between language and color\n",
    "language_color_dict = {}\n",
    "for i, language in enumerate(languages):\n",
    "    language_color_dict[language]=paired[i]\n",
    "# Create dict between language and countries\n",
    "language_country_dict = {}\n",
    "for index, row in language_country.iteritems():\n",
    "    if row in language_country_dict:\n",
    "        language_country_dict[row].append(index)\n",
    "    else:\n",
    "        language_country_dict[row]=[index]\n",
    "\n",
    "data = []\n",
    "for i, lang in enumerate(languages):\n",
    "    trace1 = go.Choropleth(\n",
    "        z=['1']*len(language_country_dict[lang]),\n",
    "        autocolorscale=False,\n",
    "        colorscale=[[0, 'rgb(255,255,255)'], [1, language_color_dict[lang]]],\n",
    "        hoverinfo='text',\n",
    "        locations=language_country_dict[lang],\n",
    "        name=lang,\n",
    "        showscale=False,\n",
    "        text=lang\n",
    "    )\n",
    "    data.append(trace1)\n",
    "layout = dict(\n",
    "    title = 'Most represented programming language per country',\n",
    "    geo = dict(\n",
    "            projection = dict(\n",
    "                type = 'Mercator'\n",
    "            ),\n",
    "            showframe=False\n",
    "            )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see on this map the real importance of StackOverflow for Javascript developers around the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Satisfaction\n",
    "In this case, we wanted to see how satisfied of their job the people in our dataset are. We compared the job satisfation with the career satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the satisfaction of each surveyee\n",
    "jobSat = stack['JobSatisfaction']/stack['JobSatisfaction'].max()\n",
    "carrSat = stack['CareerSatisfaction']/stack['CareerSatisfaction'].max()\n",
    "j = jobSat.value_counts(normalize=True).sort_index()\n",
    "carr = carrSat.value_counts(normalize=True)\n",
    "c = carr.loc[j.index]\n",
    "df = pd.DataFrame([j, c])\n",
    "df = df.T\n",
    "df.columns = [\"Job Satisfaction\", \"Career Satisfaction\"]\n",
    "df.plot.bar(figsize=(7,7))\n",
    "plt.title('Satisfaction')\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It is pretty clear on the graph above that the job satisfaction and the career satisfaction are directly linked. To remove all bias such as a person that votes 4 for the job and 8 for the career while another person votes 8 for the job and 4 for the career, we decided to look at the difference between these values and see if we have a lot of people having that much difference between their satisfactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "satisfaction = stack[['JobSatisfaction','CareerSatisfaction']]\n",
    "satisfaction['Difference']= np.abs(satisfaction['JobSatisfaction']-satisfaction['CareerSatisfaction'])\n",
    "satisfaction['Difference'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in general people give approximately the same satisfaction score to their job and to their career. It means that the distribution seen above is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep the columns liked to satisfaction, \n",
    "# we mean them together and normalize the result\n",
    "satisfaction_mean = prof_stack[[\"JobSatisfaction\", \"CareerSatisfaction\"]].mean(axis=1)\n",
    "satisfaction_mean = (satisfaction_mean - satisfaction_mean.min()) / (satisfaction_mean.max() - satisfaction_mean.min())\n",
    "\n",
    "# Separate the other factors\n",
    "other_factors = prof_stack.drop([\"StackOverflowSatisfaction\", \"CareerSatisfaction\", \"JobSatisfaction\", \"ExpectedSalary\"], axis=1)\n",
    "other_factors = other_factors.fillna(\"\")\n",
    "\n",
    "# In order to measure the correlation we need \n",
    "# to encode the labels need to encode the \n",
    "# labels to measure the correlation\n",
    "for c in other_factors.columns:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(other_factors[c])\n",
    "    other_factors[c] = le.transform(other_factors[c])\n",
    "    \n",
    "# Which columns does the satisfaction correlate the most with ?\n",
    "most_satisfactory = other_factors.corrwith(satisfaction_mean).nlargest(10)\n",
    "most_satisfactory.plot.bar()\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.xlabel(\"Other factors\")\n",
    "plt.title(\"Column correlation for the measure of satisfaction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we can see that the more people have a high salary, the more satisfied they are. Interestingly, it also correlates with general welness at work, for example the equipment, or the environnement, but also with their free time ! They see to be more happy if they program as a hobby and if they build stuff on their own. Finally, obviously the biggest factors like Country, Education and Race matter a lot too, which was to be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity Important\n",
    "In this section we will analyze if professionals and students give the same importance to the diversity at their job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stud_prof(prof_stack=prof_stack, stud_stack=stud_stack, column='DiversityImportant', title=\"Diversity Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can pretty easily see that the two distributions are really close and it seems to not be different between professionals and students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salaries\n",
    "Let's take a look at how the salaries compare for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (box, dist) = plt.subplots(nrows=1, ncols=2, figsize=(10,6))\n",
    "f.subplots_adjust(wspace=0.7)\n",
    "\n",
    "# Boxplot of the salaries\n",
    "sns.boxplot(prof_stack.Salary, orient='v', ax=box)\n",
    "box.set_title(\"Box-plot of the total salaries\")\n",
    "\n",
    "# Comparing India and the USA salary-wise\n",
    "usa_salary = prof_stack[prof_stack.Country == \"United States\"].Salary\n",
    "usa_salary.rename(\"United States\", inplace=True)\n",
    "india_salary = prof_stack[prof_stack.Country == \"India\"].Salary\n",
    "india_salary.rename(\"India\", inplace=True)\n",
    "india_salary.plot.kde(legend=True, ax=dist)\n",
    "usa_salary.plot.kde(legend=True, ax=dist)\n",
    "dist.set_title(\"Salary distribution\")\n",
    "dist.set_xlabel(\"Salary in USD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the boxplot shows that we have a high breadth of salaries. If we compare the distribution of two different countries, we can see why, each country simply have their own revenue model for the profession. What about the students, do they their salary expectation meet the reality or not ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compare the student expectations to the young professionals\n",
    "stud_stack.ExpectedSalary.plot(kind='kde', figsize=(10,8), color='r', legend=True)\n",
    "prof_stack[(prof_stack.YearsProgram == \"Less than a year\")].Salary.plot(kind='kde', figsize=(7,7), legend=True)\n",
    "plt.xlabel(\"Salary/Expected Salary in USD\")\n",
    "plt.title(\"Distribution of expected salary and salary for the students and professionals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, they match quite nicely ! Students are not the highest dreamers after all.\n",
    "\n",
    "Another really important aspect concerning the salary is the equality inbetween women and men. Let's verify that it holds for the StackOverflow community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_salary = stack[stack.Gender == \"Female\"].Salary\n",
    "male_salary = stack[stack.Gender == \"Male\"].Salary\n",
    "male_salary.rename(\"Male\", inplace=True)\n",
    "female_salary.rename(\"Female\", inplace=True)\n",
    "print(\"There are {} male samples and {} female samples.\".format(male_salary.count(), female_salary.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the samples are really unequal, so it would be unwise to try and draw any conclusions as the salaries are supposedly quite close to one another. We decided instead to take it very seriously and run a pairwise-matching to find a one to one mapping of each woman to a man, without taking into account the salary, and then check the distributions. This way the comparisons will make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We select the columns to use as features\n",
    "similarity_features = ['Country', 'University',\n",
    "       'EmploymentStatus', 'FormalEducation', 'CompanySize',\n",
    "       'CompanyType', 'YearsCodedJob', 'DeveloperType',\n",
    "       'WebDeveloperType', 'NonDeveloperType',\n",
    "       'EducationTypes', 'HaveWorkedLanguage', 'Methodology',\n",
    "       'HighestEducationParents', 'Race']\n",
    "\n",
    "# The following columns we want a 1 to 1 matching for\n",
    "# as they are the most important features\n",
    "perfect_matches = ['Country', 'EmploymentStatus', 'FormalEducation', \n",
    "                   'YearsCodedJob','HighestEducationParents', 'Race']\n",
    "\n",
    "sim_stack = prof_stack[similarity_features].copy()\n",
    "to_dummy = [\"HaveWorkedLanguage\", \"DeveloperType\", \"Methodology\", \"EducationTypes\", \"NonDeveloperType\", \"Race\"]\n",
    "for sub in to_dummy:\n",
    "    sim_stack[sub] = sim_stack[sub].apply(lambda x: str(x).replace(\" \", \"\").split(\";\"))\n",
    "    if sub == \"Race\":\n",
    "        sim_stack[sub] = sim_stack[sub].apply(lambda x: [\"Race_\" + s for s in x])\n",
    "    sim_stack = pd.concat([sim_stack, pd.get_dummies(pd.DataFrame(sim_stack[sub].tolist(), index=sim_stack.index).stack()).sum(level=0)], axis=1).drop(sub, axis=1)\n",
    "\n",
    "# Final dummies we will be using\n",
    "dummied_prof = pd.get_dummies(sim_stack)\n",
    "dum_female = dummied_prof[prof_stack.Gender == \"Female\"]\n",
    "dum_male = dummied_prof[prof_stack.Gender == \"Male\"]\n",
    "\n",
    "# We load the data from a pickle for\n",
    "# speed otherwise, change the constant\n",
    "load_from_pickle = False\n",
    "matching = pd.DataFrame(index=dum_female.index, columns=[\"male_matched\", \"correlation\"])\n",
    "for i,fem in enumerate(matching.index):\n",
    "    print(\"Progress: {:.2f}%\".format((i+1)/matching.shape[0]*100), end=\"\\r\")\n",
    "    # We match the following female\n",
    "    female_to_match = dum_female.loc[fem]\n",
    "\n",
    "    # We want an exact match for the \n",
    "    # specified columns in the previous cell\n",
    "    perfect_columns = [col for c in perfect_matches for col in dum_male if col.startswith(c) ]\n",
    "    male_possibilities = dum_male[(dum_male[perfect_columns] == female_to_match[perfect_columns]).all(axis=1)]\n",
    "\n",
    "    # For the other columns, we select \n",
    "    # the closest sample correlation-wise\n",
    "    correlations = male_possibilities.drop(perfect_columns, axis=1).corrwith(dum_female.drop(perfect_columns, axis=1).loc[fem], axis=1)\n",
    "\n",
    "    # If we find no perfect match, the\n",
    "    # female sample is discarded\n",
    "    if correlations.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    # Select the best male match and remove \n",
    "    # it from all possible matches\n",
    "    best_match = correlations.idxmax()\n",
    "    dum_male.drop(best_match, inplace=True)\n",
    "    matching.loc[fem][\"male_matched\"] = best_match\n",
    "    matching.loc[fem][\"correlation\"] = correlations.max()\n",
    "\n",
    "# Remove the unmatched pairs\n",
    "matching.dropna(inplace=True)\n",
    "\n",
    "matching = matching.reset_index()\n",
    "matched_indices = matching.T.iloc[0].tolist() + matching.T.iloc[1].tolist()\n",
    "matched_data = prof_stack.loc[matched_indices]\n",
    "male_salary = matched_data[matched_data.Gender == \"Male\"].Salary\n",
    "female_salary = matched_data[matched_data.Gender == \"Female\"].Salary\n",
    "male_salary.rename(\"Male\", inplace=True)\n",
    "female_salary.rename(\"Female\", inplace=True)\n",
    "\n",
    "# Let's plot it\n",
    "male_salary.plot.kde(color=\"r\", legend=True, figsize=(10,8))\n",
    "female_salary.plot.kde(legend=True, figsize=(10,8))\n",
    "plt.title(\"Distribution of male and female salaries\")\n",
    "plt.show()\n",
    "\n",
    "# We perform a Kolmogorov-Smirnoff test\n",
    "statistic, p_value = ks_2samp(female_salary, male_salary)\n",
    "print(\"We get a statistic of {:.4f} and a p_value of {:.4f} for {} male samples and {} female samples.\"\n",
    "     .format(statistic, p_value, male_salary.count(), female_salary.count()))\n",
    "\n",
    "# We also take a look at the quartiles\n",
    "\n",
    "print(\"\\nThe male salaries quartiles:\\n{}\".format(male_salary.describe()))\n",
    "print(\"\\nThe female salaries quartiles:\\n{}\".format(female_salary.describe()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the p-value is above the 0.05 threshold we cannot reject the hypothesis that the salary samples are drawn from the same distribution. Which is confirmed by the low statistic. We can also see that the distribution of the female salaries is a bit to the left compared to the men one, which is confirmed by the quartiles, where we see the men winning mostly in that regard.\n",
    "\n",
    "Still, we should be reminded of the fact that we have only 447 samples of each population, which might not be enough to base any conclusion off of.\n",
    "## Personal Attributes\n",
    "To get a final feel of the data, we take a look at the distribution of genders and races of the respondents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (race, gender) = plt.subplots(nrows=1, ncols=2, figsize=(10,6))\n",
    "f.subplots_adjust(wspace=0.7)\n",
    "\n",
    "prof_stack.Race.value_counts(normalize=True)[0:6].plot(kind='bar', ax=race)\n",
    "race.set_title(\"Distribution of the races\")\n",
    "race.set_ylabel(\"Ratio\")\n",
    "\n",
    "prof_stack.Gender.value_counts(normalize=True)[0:4].plot(kind='bar', ax=gender)\n",
    "gender.set_title(\"Distribution of the genders\")\n",
    "gender.set_ylabel(\"Ratio\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no surprise, the majority of respondents are white males.\n",
    "## Education types\n",
    "Another interesting thing to know is how these developers learned to code. Do the students and professionals learned the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_education = pd.Series([ed for sublist in [str(educs).replace(\" \", \"\").split(\";\") for educs in prof_stack['EducationTypes'].dropna()] for ed in sublist])\n",
    "stud_education = pd.Series([ed for sublist in [str(educs).replace(\" \", \"\").split(\";\") for educs in stud_stack['EducationTypes'].dropna()] for ed in sublist])\n",
    "plot_stud_prof(prof=prof_education, stud=stud_education, title=\"Education types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again without any surprise, the distributions are quite the same, appart from the ones linked to the job/student life, for example students are more likely to learn using online courses and professional using on-the-job training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIF vs JIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gif_df = stack[[\"PronounceGIF\", \"Salary\"]].dropna(how='any')\n",
    "gif_df = gif_df.set_index(\"PronounceGIF\")\n",
    "g_df = gif_df.loc['With a hard \"g,\" like \"gift\"'].Salary.values\n",
    "j_df = gif_df.loc['With a soft \"g,\" like \"jiff\"'].Salary.values\n",
    "comparing_df = pd.DataFrame()\n",
    "comparing_df['gif'] = pd.Series(g_df)\n",
    "\n",
    "# We fill the empty values\n",
    "filling = np.empty((6081))\n",
    "filling[:] = np.nan\n",
    "to_add = np.append(j_df, filling)\n",
    "comparing_df['jif'] = pd.Series(to_add)\n",
    "\n",
    "# Let's check it out\n",
    "plot = sns.boxplot(data=comparing_df, orient=\"v\",)\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.title(\"Distribution of salary for the gif and jif populations\")\n",
    "plt.show()\n",
    "\n",
    "print(comparing_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ECRIS LA MATTHIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep important features\n",
    "important_features_prof = ['ProgramHobby', 'Country', 'University', 'FormalEducation', 'MajorUndergrad', 'CompanyType'\n",
    "                           ,'YearsCodedJob', 'YearsProgram', 'DeveloperType', 'CareerSatisfaction', 'JobSatisfaction', 'Overpaid'\n",
    "                           , 'HaveWorkedLanguage', 'WantWorkLanguage']\n",
    "\n",
    "\n",
    "important_features_stud = ['ProgramHobby', 'Country', 'University', 'FormalEducation', 'YearsProgram','WorkStart',\n",
    "                            'HaveWorkedLanguage', 'WantWorkLanguage', 'AuditoryEnvironment']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_prof_stack = prof_stack[important_features_prof].copy()\n",
    "final_stud_stack = stud_stack[important_features_stud].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummies the dataframe\n",
    "def dummies(df, columns, special_col):\n",
    "        \n",
    "    for sub in columns:\n",
    "        df[sub] = df[sub].apply(lambda x: str(x).replace(\" \", \"\").split(\";\"))\n",
    "        if sub == special_col:\n",
    "            df[sub] = df[sub].apply(lambda x: [\"Want_\" + s for s in x])\n",
    "        df = pd.concat([df, pd.get_dummies(pd.DataFrame(df[sub].tolist(), index=df.index).stack()).sum(level=0)], axis=1).drop(sub, axis=1)\n",
    "    df = pd.get_dummies(df)\n",
    "    return df\n",
    "\n",
    "#Preprocess dataframe (dummies and nan)\n",
    "def preprocessed(df, columns, special_col, prof):\n",
    "    df = df.dropna()\n",
    "    final_df = dummies(df.copy(), columns, special_col)\n",
    "    if prof:\n",
    "        final_df.JobSatisfaction /= 10\n",
    "        final_df.CareerSatisfaction /= 10\n",
    "    return final_df, df\n",
    "\n",
    "def compute_knn_graph(df):\n",
    "    graph = kneighbors_graph(df, int(np.sqrt(df.shape[0])), mode='distance', include_self=True)\n",
    "    graph.data = np.exp(- graph.data ** 2 / (2. * np.mean(graph.data) ** 2))\n",
    "    return graph\n",
    "                             \n",
    "def draw_graph(graph):\n",
    "    \n",
    "    G = nx.from_scipy_sparse_matrix(graph,edge_attribute='similarity')\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=7)\n",
    "    plt.show()\n",
    "    return G, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dfs_stud = preprocessed(final_stud_stack, [\"HaveWorkedLanguage\", \"WantWorkLanguage\"],\n",
    "                                          'WantWorkLanguage', False)\n",
    "G_stud, pos_stud = draw_graph(compute_knn_graph(preprocessed_dfs_stud[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dfs_prof = preprocessed(final_prof_stack, [\"HaveWorkedLanguage\", \"WantWorkLanguage\", 'DeveloperType'],\n",
    "                                          'WantWorkLanguage', True)\n",
    "G_prof, pos_prof = draw_graph(compute_knn_graph(preprocessed_dfs_prof[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode string label to int\n",
    "def encode_label(df, features):\n",
    "\n",
    "    mapping_prof = []\n",
    "    df_encode = df.copy()\n",
    "    for c in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(df_encode[c])\n",
    "        df_encode[c] = le.transform(df_encode[c])\n",
    "        le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    \n",
    "        mapping_prof.append(le_name_mapping)\n",
    "        \n",
    "    return mapping_prof, df_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_stud, df_encode_stud = encode_label(preprocessed_dfs_stud[1], important_features_stud)\n",
    "map_prof, df_encode_prof = encode_label(preprocessed_dfs_prof[1], important_features_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot graph by features\n",
    "def draw_features(important_features, df, mapping, G, pos):\n",
    "    for i,features in enumerate(important_features):\n",
    "        print(features)\n",
    "        f = plt.figure(1,figsize=(10,10))\n",
    "        norm = plt.Normalize()\n",
    "        cmap = plt.get_cmap('Set2')\n",
    "        c = cmap(norm(list(df[features])))\n",
    "        if i in [0,2]:\n",
    "            scalarMap = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "        \n",
    "            ax = f.add_subplot(1,1,1)\n",
    "   \n",
    "            for label in mapping[i]:\n",
    "                ax.plot([0],[0],color=scalarMap.to_rgba(mapping[i][label]),label=label)\n",
    "    \n",
    "        nx.draw_networkx_nodes(G, pos, node_color=c, node_size=20)\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_features(important_features_stud, df_encode_stud, map_stud, G_stud, pos_stud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_features(important_features_prof, df_encode_prof, map_prof, G_prof, pos_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_neighbors(G, pos, node):\n",
    "    color = ['r'] * len(G.node)\n",
    "    color[node] = 'b'\n",
    "    for n in G.neighbors(node):\n",
    "        if n != node:\n",
    "            color[n] = 'g'\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=color, node_size=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stud_stack.loc[final_stud_stack.shape[0]] = ['Yes, both', 'France', 'No', 'Secondary school', '2 to 3 years', '10:00 AM', 'C#, Java',\n",
    "                                                  'C++, Python', 'Turn on some music']\n",
    "predict_dfs_stud = preprocessed(final_stud_stack, [\"HaveWorkedLanguage\", \"WantWorkLanguage\"],\n",
    "                                          'WantWorkLanguage', False)\n",
    "knn_stud = compute_knn_graph(predict_dfs_stud[0])\n",
    "\n",
    "best_predict_stud = np.argsort(knn_stud.toarray()[-1])[::-1][1:6]\n",
    "size_stud = preprocessed_dfs_stud[1].shape[0]\n",
    "predict_dfs_stud[1].iloc[[size_stud-1] + list(best_predict_stud), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_stud = nx.from_scipy_sparse_matrix(knn_stud, edge_attribute='similarity')\n",
    "pos_stud = nx.spring_layout(G_stud)\n",
    "draw_neighbors(G_stud, pos_stud, size_stud-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professional "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prof_stack.loc[final_prof_stack.shape[0]] = ['Yes, both', 'United Kingdom', 'No', \"Bachelor's degree\", 'Computer science or software engineering', \n",
    "                                                   'Publicly-traded corporation', '20 or more years', '20 or more years', 'Other', \n",
    "                                                   8.0, 9.0, 'Neither underpaid nor overpaid', 'Java; PHP; Python', \n",
    "                                                   'C; Python; Rust']\n",
    "\n",
    "predict_dfs_prof = preprocessed(final_prof_stack, [\"HaveWorkedLanguage\", \"WantWorkLanguage\", \"DeveloperType\"],\n",
    "                                          'WantWorkLanguage', True)\n",
    "\n",
    "knn_prof = compute_knn_graph(predict_dfs_prof[0])\n",
    "best_predict_prof = np.argsort(knn_prof.toarray()[-1])[::-1][1:6]\n",
    "\n",
    "size_prof = preprocessed_dfs_prof[1].shape[0]\n",
    "predict_dfs_prof[1].iloc[[size_prof-1] + list(best_predict_prof), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_prof = nx.from_scipy_sparse_matrix(knn_prof, edge_attribute='similarity')\n",
    "pos_prof = nx.spring_layout(G_prof)\n",
    "draw_neighbors(G_prof, pos_prof, size_prof-1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
